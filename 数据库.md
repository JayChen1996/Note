[toc]

# 关系数据库设计理论

## 函数依赖

- **函数依赖**：若A决定B，则B函数依赖于A
- **键码**：决定了关系的其他所有属性的一个最小属性集合
- **完全函数依赖**：A是决定B的最小集合，没有A的真子集能够决定B
- **传递函数依赖**：若C函数依赖于B，B函数依赖于A，则C函数依赖于A



## 范式

### 不满足范式产生的异常

- 冗余数据
- 修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。
- 删除异常：删除一个信息，那么也会丢失其它信息。
- 插入异常：如果插入的信息其他属性当前未知则无法插入

### 范式

1. **第一范式**：属性不可分
2. **第二范式**：每个非主属性完全函数依赖于键码
3. **第三范式**：非主属性不传递依赖于键码



# 事 务

- 数据库中满足ACID的一组操作序列。



## ACID

- ==原子性（Atomicity）==：事务被视为不可分割的最小单元，要么全部成功，要么全部失败。
- ==一致性（Consistency）==：数据库总是从一个正确状态迁移到另一个正确状态，其完整性不会被破坏
- ==隔离性（Isolation）==：并发执行的事务相互独立，其修改只有在提交后才对其他事务可见
- ==持久性（Durability）==：事务对数据的修改是永久的，即便系统故障也不会丢失。

> MySQL 默认采用自动提交模式。如果不显式使用`START TRANSACTION`语句来开始一个事务，那么每个查询操作都会被当做一个事务并自动提交。



## 并发一致性

- ==丢失修改==：修改被另一事务覆盖
- ==读脏数据==：读到其他事务修改的数据后，其他事务撤销了该修改
- ==不可重复读==：读数据后，其他事务修改了该数据，再次读结果不同
- ==幻影读==：读某个范围内的数据后，其他事务在此范围内插入了新数据，再次读结果不同

### 产生原因

- 由于破坏了事务的隔离性

### 解决方法

- 通过并发控制来保证隔离性
  - ==封锁==：需要用户自己控制，相当复杂
  - ==事务隔离级别==



## 封锁

### 封锁粒度

MySQL 中提供了三种封锁粒度：==行级锁==、==页级锁==（BDB引擎）、==表级锁==。

- 应尽量只锁定需要修改的那部分数据
- 锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高，开销越大。

### 封锁类型

1. ==读写锁==

   - 互斥锁（Exclusive）：写锁，简称X锁
   - 共享锁（Shared）：读锁，简称S锁

   读锁间不互斥，写锁间互斥，读写锁互斥。

2. ==意向锁==（IX锁/IS锁）

   - 只用X/S锁对表加锁时需要检测每一行是否加锁，很耗时。

   - 获取X锁之前必须获取==表的IX锁==，获取S锁之前必须获取==表的IS锁==。

   - IS/IX 锁之间不互斥，IS/IX锁对表级X/S锁互斥，对行级X/S锁不互斥。

3. 悲观锁

4. 乐观锁

### 封锁协议

1. 三级封锁协议
   - 一级封锁协议：事务修改数据时必须加X锁，事务结束后释放：==解决丢失修改==
   - 二级封锁协议：在一级基础上，事务读数据必须加S锁，==读完马上释放==：==解决读脏数据==
   - 三级封锁协议：在二级基础上，事务读数据必须加S锁，==事务结束后释放==：==解决不可重复读==

2. 两段锁协议

   - 加锁和解锁分为两个阶段进行：加锁阶段对所有资源加锁、解锁阶段对所有资源解锁。
- ==两段锁协议是保证可串行化调度的充分不必要条件==。
   - ==可串行化调度==：通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。串行执行的事务互不干扰，不会出现并发一致性问题。



## 事务隔离级别

- ==未提交读==：事务未提交的修改对其他事务可见
- ==提交读==：事务未提交的修改对其他事务不可见：==解决脏读==
- ==可重复读==：在同一个事务中多次读取同一数据的结果是一样的：==解决不可重复读==
- ==可串行化==：加锁实现事务串行执行，务互不干扰，==不会出现并发一致性问题==



# 索引

- 相当于查字典，先查该字在那个区间，能够提高查询速度。

- ==最左前缀匹配原则==：从左向右匹配索引列，直到遇到范围查询j就停止匹配（<, >, BETWEEN, LIKE）



## 索引类型

### 两大类

1. **聚簇索引**
   - 按索引值组织实际数据存放物理位置，相邻索引值的数据存储位置相邻；
   - 叶子节点包含所有数据
   - 一个表只有能一个聚簇索引
   - 多行检索速度快
   - 字符串类型不宜建立聚簇索引，特别是随机字符串，会使得系统进行大量的移动操作

2. **非聚簇索引**
   - 叶子节点有指向对应数据块的指针
   - 单行数据操作快

### 四小类

1. **普通索引**：
   - 最基本索引，无任何限制；
2. **唯一索引**：
   - 索引列的值必须唯一，但允许有空值；若为组合索引，则列值的组合必须唯一；
3. **全文索引**：
   - 关键字匹配，对于大量文本数据比like快
   - 只能从CHAR、VARCHAR及TEXT创建
   - 数据长度小于最小搜索长度或大于最大搜索长度不会创建索引
   - 对于大量数据，先添加数据，再创建索引，这样更快；
   - 两种模式：
     - 自然语言模式：基于相关度及关键词出现次数匹配，不匹配出现次数过多的词
     - 布尔模式：可自定义相关性
4. **组合索引**
   - 将多列组合成一个索引
   - 使用最左匹配原则：若不是按照索引列的顺序进行查找，则无法使用索引



## 索引数据结构

1. B+树索引
   - 大多数MySQL存储引擎的默认索引数据结构
   - 先在节点找到key所在区间的指针，到下一个节点重复次步骤，直到到叶子节点，找到对应数据
   - 有序，可用于排序和分组
   - O(log(N))时间复杂度
   - 对比红黑树，优点：
     - 更少I/O次数：查找时间复杂度由I/O次数决定，I/O次数由高度h决定，高度由出度d决定，B+树出度一般很大：O(I/O)=O(h)=O(log~d~N)
     - 利用磁盘预读特性：将索引节点设置成页的大小，预读相邻的页
2. 哈希索引
   - O(1)时间复杂度查找
   - 无序：无法用于排序和分组；只能精确查找，无法部分查找和范围查找
   - InnoDB自适应哈希索引：当某个索引值使用非常频繁，则会在 B+Tree 索引之上再创建一个哈希索引
3. 全文索引
   - 使用倒排索引实现，记录关键词到所在文档的映射
4. 空间数据索引
   - MyISAM支持（R-Tree)
   - 用于地理数据存储
   - 从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。
   - 必须使用 GIS 相关的函数来维护数据。



## 索引优点（B+树)

1. 无需全表扫描，大大减小扫描数据量
2. 避免服务器进行排序和和分组，以避免创建临时表
3. 将随机I/O变为顺序I/O



## 索引优化

1. 高区分度列放前面：区分度越高，查询效率越高（最左匹配总是从前面开始匹配）
2. 最左前缀匹配原则：将范围查找的索引放后面
3. 组合索引：单个多列索引比多个单列索引好，因为执行时MySQL只能使用一个索引
4. 扩展索引：尽可能在现有索引上进行扩展，不建立新索引。比如已有(a)时建立(a, b)索引
5. 前缀索引：对于BLOB、TEXT及VARCHAR类型的列（必须），只索引开始部分字符
6. 覆盖索引：索引包含所有需要查询的字段的值
   - 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
   - MyISAM：内存只缓存索引，而数据依赖于操作系统缓存；覆盖索引可不使用系统调用
   - InnoDB：若辅助索引能够覆盖查询，则无需访问主索引



## 查询优化

- 用EXPLAIN关键词分析执行时的查询类型、顺序、使用的索引等信息，然后优化查询
- MySQL 5.0后可使用 show profile 查看SQL语句的资源开销

1. 减少请求数据量
   - 只返回必要的列：只返回需要的字段，最好不用SELECT *
   - 只返回必要的行：用LIMIT限制返回行数
   - 缓存重复查询的数据
2. 减少扫描行数：
   - 索引列不参与计算：索引列参与计算会导致不能使用该索引
   - 若要排序，让排序的表优先查
   - 切分大查询：大查询会一次锁住很多数据，阻塞小的重要查询
   - 分解大连接查询：对单表进行查询，然后在应用程序中进行关联：
     - 让缓存更高效：连接查询中一个表发生变化整个查询缓存就无法使用
     - 单表查询的缓存可以被其他查询使用到
     - 减少锁竞争
     - 在应用层连接，更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。
     - 本身效率可能提升：可能按索引值顺序进行查找，比连接的随机查找效率高



## 索引的适用场景

- 中大型表，索引非常有效
- 对于小型表，全表扫描效率大部分情况下效率更高
- 对于特大型表：建立和维护索引的代价会随之增长，需要用到如分区技术等直接区分出需要查询的一组数据。



# MySQL

## 存储引擎

### InnoDB

#### 特点

1. 事务：

   - 实现了四个隔离级别，默认可重复读级别
   - 在可重复读级别下通过MVCC + Next-Key Locks防止幻影读

2. 并发：

   - 支持行级锁和表级锁

3. 索引：

   - 主索引为聚簇索引，索引中保存数据，避免直接读取磁盘，性能较高
   - 二级索引叶子节点存主键值：通过二级索引查到主键值，再到主索引查找具体数据
   - 自适应哈希索引：对高频索引值建立哈希索引

4. 其他：

   - 支持在线热备份：其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

   - 支持外键



#### 多版本并发控制（Multi-Version Concurrency Control, MVCC）

- MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式
- 用于实现==提交读==和==可重复读==这两种隔离级别。
- ==多版本思想==：写操作更新最新版快照，读操作读旧快照，==避免读锁与写锁之间的互斥==
- ==避免了读操作的加锁==

1. 版本号

   - 系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。

   - 事务版本号 TRX_ID ：事务开始时的系统版本号。

2. Undo 日志：储存多个版本的快照，通过回滚指针ROLL_PTR把一个数据行的快照连接起来

3. ReadView结构
   - 储存事务开始时当前系统中活动的事务ID列表及其最小值 TRX_ID_MIN 和 TRX_ID_MAX。
   - 各种事务隔离级别下的ReadView工作方式
     - READ_UNCOMMITTED未提交读：事务不会获取ReadView 副本。
     - RC提交读：同一个事务每一次查询都会获得一个新的read view副本：不可重复读问题
     - RR重复读：一个事务只会获取一次read view副本，保证每次查询的数据都是一样的。

4. 判断快照是否可用
   - 读时根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 判断该快照是否可用：
     - TRX_ID < TRX_ID_MIN：该数据行快照时在当前所有活动事务之前更改的，可以使用
     - TRX_ID > TRX_ID_MAX：该数据行快照是在所有活动事务启动之后被更改的，不可用。
     - TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。
   - 数据行快照不可用时，沿着Undo Log的回滚指针找到下一个快照，再进行判断。

5. 快照读和当前读
   - 快照读：SELECT操作快照中的数据，无需加锁；
   - 当前读：修改操作读取的是最新的数据，需要加锁；



#### Next-Key Locks

- InnoDB的一种锁实现
- 在可重复读隔离界别下，使用==MVCC + Next-Key Locks== 可以解决==幻影读==问题。

1. Record Locks：锁定一个记录上的索引，而不是记录本身。

2. Gap Locks：锁定两索引之间的间隙范围，但是不包含索引本身。

3. Next-Key Locks
   - Record Locks 和 Gap Locks 的结合
   - 不仅锁定一个记录上的索引，也锁定索引之间的间隙范围
   - 锁定一个==前开后闭区间==



### MyISAM

#### 特点

1. 不支持事务：

   - 修复操作：与事务恢复和崩溃恢复不同，可能导致一些数据丢失，且非常慢

2. 并发：

   - 只支持表级锁：读时对表加共享锁，写时加互斥锁

   - 并发插入：在表有读取操作时，也可以往表中插入新纪录

3. 索引：

   - 主索引与二级索引都是非聚簇索引，叶子节点存指向存放数据物理快的指针
   - 支持空间数据索引

4. 其他：

   - 支持压缩表



### InnoDB 与 MyISAM 对比

1. 事务：

   - InnoDB是事务型数据库，能够回滚
   - MyISAM不支持事务，其修复操作可能丢失数据，损坏率高，修复速度慢

2. 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。

3. 索引：

   - MyISAM主索引与二级索引都是非聚簇索引，叶子节点存指向存放数据物理快的指针
   - InnoDB主索引为聚簇索引，二级索引叶子节点存主键值
   - MyISAM支持空间数据索引，InnoDB支持自适应哈希索引

4. 其他特性：

   - InnoDB：支持外键、在线热备份
   - MyISAM：支持压缩表

   

## 常见数据类型

### 整型

1. TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间；

### 小数

1. FLOAT 和 DOUBLE： 浮点类型，其运算CPU 原生支持；分别为8、4字节
2. DECIMAL：高精度小数类型，其计算无CPU原生支持 ，因此代价更高
3. 都支持指定列宽：如 DECIMAL(18, 9) 表示共 18 位，取 9 位存储小数部分；

### 字符串

1. CHAR：定长，检索和存储时，末尾空格会被删除
2. VARCHAR：变长，节省空间。
   - 若长度增长得超过一个页的极限时，需要执行额外操作：
     - MyISAM：将行拆成不同的片段存储；
     - InnoDB：分裂页以使行放进页内。
   - 5.0以上，最长长度为2^16^=65535，起始位占3字节，数据最大长度65532
   - 5.0以上VARCHAR(20)指20个字符不是20个字节
   - 插入数据超过设置长度，超过部分会被截断
   - 查询速度慢于CHAR
3. TINYTEXT、TEXT、MEDIUMTEXT、LONGTEXT
   - 可变长度，最长分别为255、65535、2^24^-1、2^32^-1
   - 与VARCHAR相比：
     - 不可设置n
     - 不能有默认值
     - 创建索引需要指定前多少个字符
     - 查询速度慢于VARCHAR
4. TINYBLOB、BLOB、MEDIUMBLOB、LONGBLOB：
   - 二进制大对象
   - 最长分别为：255B，65K、16M、4G

### 时间

1. DATETIME：

   - 8字节，
   - 时区无关，
   - 保存1000-9999年的日期和时间，精度为秒

2. TIMESTAMP：

   - 4字节，空间效率更高
   - 时区相关，
   - 和 UNIX 时间戳相同，保存1970.01.01以来的秒数，表示范围1970-2038 年。
   - 插入时若为空，默认设置为当前时间戳

   

## 数据切分

- 由于单机存储容量、连接数、处理能力有限，当数据量过大时，需要考虑数据切分
- 本质时将数据分散存储到多个数据库中，是单库数据量变小

### 垂直切分

可分为垂直分库和垂直分表：

1. 垂直分库：关联度低的不同表存储在不同的数据库
2. 垂直分表：将一张表按列切分成多个表
   - 按关系密集程度进行切分、按常使用和不常使用切分
   - 便于开发和维护；避免跨页，提升性能；减小锁竞争，提高并发性

#### 问题

1. 依然存在单表数据量过大的问题（需要水平切分）
2. 事务性：通过分布式事务来解决，如XA接口

### 水平切分（Sharding）

当一个应用难以再细粒度的垂直切分，或切分后数据量行数巨大，需要进行水平切分

1. 库内分表：按行切分，将同一个表中的记录拆分到同库的多个结构相同的表中。
2. 分库分表：按行切分，将同一个表中的记录拆分到多个库的结构相同的表中。

#### 策略

1. 哈希取模：hash(key) % N；
2. 范围：可以是 ID 范围也可以是时间范围；
3. 映射表：使用单独的一个数据库来存储映射关系。

#### 问题

1. 事务性：通过分布式事务来解决，如XA接口
2. 连接查询：单表查询后在应用程序中进行连接，提高了开发复杂度
3. ID唯一性：只用全局唯一ID、为每个分片指定一个 ID 范围或使用分布式 ID 生成器 



## MySQL的复制机制

### 复制流程

三个线程：

1. **binlog 线程** ：将主服务器上的数据更改写入二进制日志（Binary log）中。

2. **I/O 线程** ：从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。
3. **SQL 线程** ：读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。

### 读写分离

1. 通常通过代理方式实现：代理服务器接收读写请求，然后决定转发到哪个服务器。
2. 主服务器：处理写操作以及实时性要求比较高的读操作，
3. 从服务器：处理读操作。
4. 优点：
   - 读写分离，缓解了锁竞争
   - 从服务器可以使用MyISAM，提升查询性能，节约系统开销
   - 增加冗余，提高可靠性



# Redis

- 非关系型内存数据库
- 速度非常快
- 键值对类型存储，键为字符串，值支持五种数据类型：STRING, LIST, SET, HASH, ZSET



## 数据组织

### 值数据类型

1. STRING：字符串、整数或浮点数

   - 操作单个元素：set / get / del 等

   - 可对整数和浮点数进行自增或自减操作

2. LIST：有序列表

   - 可从两边压入或弹出：lpush / rpush / lpop / rpop 等
   - 单个或多个元素的范围操作：lindex / lrange 等

3. SET：无序集合

   - 单个元素增、删、改、查及判断是否存在：sadd / smembers / sismember / srem 等
   - 进行集合的交、并、差

4. HASH：键值对类型的无序hash表

   - 对单个键值对进行增、删、改、查及判断是否存在：hset / hget / hgetall / hdel 等

5. ZSET：有序集合

   - 操作单个元素或根据分值范围获取元素：zadd / zrem / zrange 等
   - 根据分值进行排序：zrangebyscore

   

### 数据结构

#### 字典 dict

- HASH的底层实现，使用拉链法解决hash冲突
- 包含连个hash表结构dictht，便于进行重散列操作：在扩容时将其中一个hash表上的键值对rehash到另一个hash表上，完成后释放空间并交换两个hash表角色
- 重散列（rehash）：hash表保存的键值对数量会随操作增减，为了让hash表的负载因子维持在一个合理的范围，需要进行rehash，即调整hash表大小并重新计算hash值
- 为了避免一次性rehash给服务器带来过大负担，采用渐进方式进行
  - 在rehash期间，每次对字典记性增删改查都会执行一次渐进式rehash
  - 渐进rehash会使数据分散在两个hash表上，因此对字典的查找要到对应hash表上执行

#### 跳跃表

- 有序集合的底层实现之一，基于多指针有序链表实现，可以看成多个有序链表
- 查找时，从上层指针开始查找，找到对应区间后在查找下一层，依次直到找到目标

- 对比红黑树、B+等平衡树：

  - 插入速度非常快：因为不需要进行旋转变色等操作来维持平衡性
  - 容易实现
  - 支持无锁操作

  

## 事务

- Redis支持事务
- 流水线：一个事务包含多个命令，一次性发送给服务器，从而减少网络通信次数，提高性能
- Redis事务最简单的实现方式为使用 MULTI 和 EXEC 命令将事务操作包围起来



## 数据淘汰

- 为了用有限的内存尽可能提高缓存命中率，保证缓存的都是热点数据，需要淘汰非热点数据
- 可以将内存最大使用量设为热点数据大小，然后通过 allkeys-lru 淘汰最近最少使用的数据

### 键过期时间

- 通过为键设置过期时间，能够在键过期时删除该键
- 对于HASH类型，只能设置整个键的过期时间，而不能设置HASH表这个值中键的过期时间

### 数据淘汰策略

当超过设置的内存最大使用量时，会实行数据淘汰策略

- volatile-lru：淘汰已设置过期时间的key中，最近最少使用的数据
- volatile-ttl：淘汰已设置过期时间的key中，最接近过期时间的数据     
- volatile-random：淘汰已设置过期时间的key中，随机的数据
-  *volatile-lfu：4.0新增，淘汰已设置过期时间的key中，访问频率最低的数据*
- allkeys-lru：：淘汰所有key中，最近最少使用的数据
- allkeys-random：淘汰所有key中，随机的数据
- *allkeys-lfu：4.0新增，淘汰所有key中，访问频率最低的数据*
- noeviction：禁止驱逐数据



## 事件

- Redis是事件驱动的数据库

### 文件事件

- 本质是对套接字操作的抽象：服务器通过套接字进行通信
- 基于Reactor模式的网络事件处理器
  - 通过I/O多路复用程序同时监听多个套接字，并将事件转发给事件分派器
  - 分派器根据事件类型调用相应的事件处理器

### 时间事件

- 本质是对需要在给定时间执行的操作的抽象
  - 定时事件：在指定时间执行一次的操作
  - 周期性事件：每隔一段时间执行一次的操作
- 将所有时间事件放在无序链表中，遍历找到已到达的时间事件，并调用相应的事件处理器

### 事件调度

- 文件事件需要不断监听，但服务器不能一直监听文件事件，否则无法及时执行时间事件
- 监听并等待文件事件产生，直到时间事件到达，处理已有的文件事件与时间事件，然后重复



## 特性

###  持久化

- 通过持久化将数据保存到磁盘上，保证数据在断电后不会丢失，提高可靠性

1. RDB持久化（Recovery DataBase）
   - 本质为快照机制：将某个时间点的所有数据都存放到硬盘上。
   - 可用于创建服务器副本：将快照复制到其它服务器
   - 可靠性不足：服务器故障会丢失最后一次创建快照之后的数据。
   - 持久化速度慢：如果数据量很大，保存快照的时间会很长。
2. AOF持久化（Append Only File）
   - 本质为附加写命令：将写命令添加到 AOF 文件的末尾。
   - 需要设置同步频率：因为写文件不会马上写到磁盘，而是存到缓冲区后由OS决定何时写到磁盘
     - always：每个写命令同步一次；会严重影响性能
     - everysec：每秒同步一次；比较合适，保证最多丢失一秒数据，且几乎不影响性能
     - no：由操作系统决定何时同步；会增加奔溃时数据丢失量，且不会提升多少性能
   - 重写特性：可去除AOF文件中冗余写命令，缓解AOF随服务器请求增多而增大的问题



### 复制

- 通过复制使一个服务器成为另一个服务器的从服务器，提高读性能；
- 一个从服务器只能有一个主服务器

1. 连接过程
   - 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令
   - 从服务器丢弃所有就数据，载入收到的快照文件，然后开始接收来自主服务器的写命令
   - 主服务器每执行一次写命令，就向服务器发送相同的写命令
2. 主从链
   - 从服务器过多或重新同步可能导致负载超载，主服务器无法及时更新所有从服务器
   - 通过建立中间层来分担主服务器负载，它是上级服务器的从服务器，也是下级服务器的主服务器
3. 哨兵（Sentinel）
   - 监听集群中的服务器，在主服务器进入下线状态时，自动在从服务器中选举出新的主服务器

### 分片

- 通过分片将数据划分为多个部分，存储到多台机器里面，提高写性能
- 选择存储实例的常见方式：
  - 范围分片：根据key范围决定存储实例，需要维护一张范围映射表，代价较高
  - 哈希分片：通过哈希函数将key转换为数字，对其求模即可知道存储实例
- 分片方式：
  - 客户端分片：在客户端出决定key分布到哪个实例节点
  - 代理分片：代理接受客户端请求，决定key存储实例，并转发请求到相应节点
  - 服务器分片：Redis Cluster



## 使用场景

**主要利用内存数据库读写性能高的特性**

1. 计数器

   - 对STRING进行自增自减从而实现计数器功能
   - 适合存储频繁读写的计数量

2. 缓存

   - 将热点数据放到内存中，提高读写性能
   - 通过设置内存最大使用量及淘汰策略来保证缓存的命中率

3. 查找表

   - 如DNS记录

   - 和缓存类似，利用了Redis快速查找的特性
   - 查找表的内容不能失效，而缓存内容可以失效，因为缓存不作为可靠数据来源

4. 会话缓存

   - 统一存储多台应用服务器的会话信息，使应用服务器专注于主要业务，不再具有状态
   - 使得用户可以请求任意应用服务器，从而实现了高可用性和可伸缩性

5. 消息队列

   - 利用LIST双向链表的特性，从两端写入和读取消息

6. 分布式锁

   - 分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。
   - 可以使用 Redis 自带的 SETNX 命令实现分布式锁或官方提供的 RedLock 分布式锁。

7. 其他

   - 利用SET的交并集操作特性，实现共同好友等功能
   - 利用ZSET的score排序特性，实现排行榜等功能



## 对比Memcached

1. 数据类型
   - Memcached只支持字符串类型；
   - Redis支持5种数据类型，更灵活
2. 数据持久化
   - Memcached不支持持久化；
   - Redis支持RDB快照和AOF日志两种持久化策略
3. 分布式
   - Memcached不支持分布式，只能在客户端通过一致性hash来实现分布式，每次都需要在客户端计算数据所在节点
   - Redis通过Cluster实现了分布式支持
4. 内存管理机制
   - Memcached所有数据一直存在内存中；其通过将内存分割成特定大小的块来解决内存碎片，但这会降低内存使用率
   - Redis会将很久没用的value交换到磁盘



## Redis数据库一致性问题

# SQL语法



# 大数据

18亿用户数据，设计一个系统根据唯一ID查找用户数据



· select for update锁的机制

· Redis、MySQL一致性问题（太喜欢问这个问题了吧，面试官还讲了个场景：活动期间导致海量用户注册，怎么解决缓存穿透问题？讲了布隆过滤器过滤未注册的用户，也提了相关的误判率，还讲了Redis/MySQL一致性的一些操作，面试官好像不太满意，解释了好久好久。）

 Redis源码（事件循环ae，单线程IO多路复用，Redis数据结构实现）