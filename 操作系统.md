[toc]

# 进程管理

## 进程与线程

### 进程

1. 本质：资源分配的基本单位，
2. 独立性：能够在系统中独立运行
3. 资源：每个进程的资源相互独立
4. 销毁：进程结束会销毁下属所有线程
5. 消耗：消耗大

### 线程

1. 本质：系统调度的基本单位，
2. 独立性：是进程中的一个实例，依赖于进程运行
3. 资源：只拥有一些运行时必不可少的资源，如程序计数器、寄存器和栈；除此之外，同进程下的所有线程共享该进程的资源，
4. 销毁：线程结束不会影响同一进程下的其他线程
5. 消耗：相当于轻量级进程，创建与销毁比进程消耗小得多
6. 数量：受内存限制
   - 操作系统给进程提供的内存一般为2G，而线程堆栈在启动时默认大小为1M,而内存实际上不可能全部用来创建线程，所以一个进程下线程的理论个数应该小于2048。当然，也可以通过连接时修改线程的默认堆栈大小来增加线程的个数上限 。



## 进程调度

- 不同环境下调度算法的目标不同。



### 批处理系统

- 批处理系统无太多用户操作，调度目标是保证吞吐量和周转时间（从提交到完成的时间）

1. 先来先服务（First Come First Serverd，FCFS）
   - 按请求顺序进行调度，
   - 非抢占式调度
   - 有利于长作业，不利于短作业（短作业等待长作业完成，等待时间过长）
2. 短作业优先（Shortest Job First，SJF）
   - 按估计运行时间最短的顺序进行调度，
   - 非抢占式调度
   - 如果一直有短作业加入，长作业可能一直等待，永远得不到调度
3. 最短剩余时间优先（Shortest Remaining Time First，SRTN）
   - 按估计剩余时间进行调度：
   - 抢占式调度
   - 新进程加入时，将其与当前进程剩余时间比较，运行时间较短的进程



### 交互式系统

- 交互式系统有大量用户交互操作，调度目标是快速进行响应

1. 时间片轮转（Round-Robin，RR）

   - 将所有进程按请求顺序排除队列，每次调度队头进程，运行一个时间片后放入队尾
   - 时间片太短会导致进程切换过于频繁，保存进程信息及载入新进程花费过多时间
   - 时间片太长会导致实时性得不到保证

2. 优先级调度（Priority-Schedule，PS）

   - 每个进程分配一个优先级，按优先级进行调度
   - 为防止优先级低的进程一直得不到调度，可随时间增加进程优先级
   - 分为非抢占式优先级调度和抢占式优先级调度

3. 多级反馈队列调度

   - RR与PS的结合：设置多个队列，越前面的队列优先级越高，时间片越短，
   - 进程在前面的队列没执行完则放入下一个队列
   - 只有在前一个队列没有进程时才会执行下一个队列
   - 既能使高优先级作业得到响应又能使短作业迅速完成

4. 完全公平调度（Completely Fair Schedule，CFS）

   - Linux 2.6内核引入的调度算法

   - 给队列中的每个进程设置了一个虚拟时钟vruntime，随该进程的执行时间增长而增长

   - 高优先级进程的vruntime增长得慢（权重实现），能够得到更多的执行机会

   - 调度器选择vruntime最小的那个来执行

     


## 进程间通信方式

### 概念

1.  每个进程有不同的用户地址空间，对其他进程不可见，进程间**交换数据必须通过内核**。
2. 在内核开辟一块**缓冲区**，进程A把数据写到缓冲区，进程B再从缓冲区把数据读走。
3. 本质是**通过公共资源进行通信**，而不同通信方式则是**提供公共资源的形式或提供者不同**。



### 管道( pipe )

1. **特点**
   - 亲缘进程间通信，如父子进程。
   - 半双工，单向通信。
   - 内部同步机制，保证访问数据的一致性。
   - 面向字节流。
   - 管道随进程而存在。进程在管道在，进程消失管道对应的端口关闭。

2. **缺点**

   - 只能承载无格式字节流

   - 缓冲区大小受限

3. **方式**
   - 父进程创建管道，得到两个⽂件描述符指向管道的两端，fd[0]为读端，fd[1]为写端。
   - 父进程fork出子进程，⼦进程也有两个⽂件描述符指向同⼀管道。
   - 一个进程关闭管道的一端，另一个则关闭管道另一端（管道是单向通信，一端读一端写）。

4. **注意**
   - 读端一直读，写端不写：读端读完数据，再次读会造成阻塞，直到管道中再次有数据可读。
   - 读端一直读，写端不写且关闭描述符：读端读完数据，再读会返回0，就像读到文件末尾。
   - 读端不读，写端一直写：管道写满数据后，再写会阻塞，直到管道有空位置时才写并返回。
   - 读端不读且关闭描述符，写端一直写：读端描述符引用计数为零，再写会收到SIGPIPE信号，导致进程异常终止。



### 有名管道 (named pipe)

1. 半双工，单向通信；
2. 允许无亲缘关系进程间通信。



### 信号 (signal)

1. 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。



### 消息队列(message queue)

1. 消息队列是消息的链表。
2. 存放在内核中并由消息队列标识符标识。
3. 添加消息到队列的末尾，接收消息在队列头部，但可以根据消息类型接受消息。
4. 消息一旦被接收，就会从队列中删除。



### 信号量(semaphore)

1. 本质上是一个计数器。
2. 不以传送数据为主要目的，主要是用来保护共享资源在一个时刻只有一个进程独享。
3. 通过同步与互斥保证访问资源的一致性。
4. 其PV操作为原子操作，单个操作不会被打断。
5. 使用时执行P操作，若计数为0，则挂起等待；计数大于0，则计数减一，获得资源使用权。
6. 释放时执行V操作，若有进程在挂起，则恢复其运行；否则计数加一。



### 共享内存(shared memory)

1. 允许不同进程共享同一段的内存，都可以对该内存进行读写。
2. 速度最快，因为数据直接写到内存，不需要在进程、内核之间复制。
3. 没有同步与互斥机制，所以要与信号量配合使用。



### 套接字(socket)

1. 可用于不同机器间的进程通信。



# 锁机制

## 线程间通信

线程间的通信目的主要是用于线程同步，所以没有像进程通信中的用于数据交换的通信机制。



### 通信方式

1. 全局变量
2. 消息通信（消息队列）
3. 信号通信（事件机制）



### 线程同步互斥机制

1. 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量

2. 锁机制：保证过临界资源访问的排他性和唯一性。

3. 条件变量：

4. - 可以以原子的方式阻塞进程，直到某个特定条件为真为止。
   - 对条件的测试是在互斥锁的保护下进行的，始终与互斥锁一起使用。

5. 

### 同步与互斥

**1. 互斥**

- 某一时刻只允许一个进程运行其中的程序片，具有排他性和唯一性。
- 对于线程来说则是：在同一时刻只允许一个线程进入临界区，对临界资源进行操作。

**2. 同步**

- 在互斥的基础上，实现进程之间对程序片的有序访问。
- 对于线程来说则是：在互斥的基础上实现线程对临界资源的有序访问。

**3. 临界资源**

- 能够被多个线程共享的数据/资源。

**4. 临界区**

- 对临界资源进行操作的那一段代码。



## 锁

### 互斥锁（Mutex）

1. 同一时刻只能有一个线程可以获取互斥锁，保证资源访问的排他性及唯一性。
2. 临界资源被锁时挂起线程，直到资源解锁该线程才被唤醒。
3. 相较自旋锁，互斥锁用于临界区持锁时间比较长的操作。



### 自旋锁（Spinlock）

1. 本质与互斥锁相同
2. 在未获得锁时不会挂起线程，而是不断循环尝试获取锁。
3. 效率高于互斥锁，但浪费CPU资源。
4. 递归调用以及调用一些其他函数时可能造成死锁。
5. 主要用在临界区持锁时间非常短且CPU资源不紧张的情况下，一般用于多核的服务器。



### 读写锁（shared_mutex)

1. 本质是一种特殊的自旋锁
2. 同一时刻只能有一个写锁或多个读锁，但不能同时既有读锁又有写锁。
3. 适合于读次数比写次数多得多的情况
4. shared_lock加读锁，unique_lock或lock_guard加写锁，upgrade_lock当读锁，必要时可以升级为写锁用。



### 悲观锁

1. 总是假设最坏的情况，每次读写数据时都认为别人会修改，所以都上锁。
2. 共享资源每次只给一个线程使用，其它线程阻塞，直到锁被释放。
3. 适用于多写时冲突几率大的情况。



### 乐观锁

#### 特点

1. 总是假设最好的情况，每次去读数据的时候都认为别人不会修改，所以不会上锁。
2. 在更新时会判断在此之前别人是否更新过这个数据，若否，则更新数据，否则就不断重试。
3. 更新判断通常使用版本号机制或CAS算法实现。
4. 适用于多读少写时冲突几率小的情况，以提高吞吐量。
5. 本质上是一种无锁编程思想，即在不用锁的情况下实现线程间的同步，非阻塞同步。



#### 版本号机制

1. 给数据附加一个版本号数据，读数据时记录版本；
2. 更新时将当前数据版本和记录的版本进行匹配；
3. 匹配则更新，否则则重新读取操作后再更新，不断重试直到成功。



#### CAS算法（Compare And Swap）

1. 读时保存内存位置V的原值A；
2. 写入新值B时比较内存位置V的值是否为预期原值A；
3. 若是，则将该位置的值设置为新值B；否则自旋重试。
4. **存在的问题**

- **ABA 问题（CAS）**

- - A值在CAS期间可能被别人更改后又改回A，但CAS不会意识到，操作存在潜在风险。

- **重试开销大（版本号、CAS）**

- - 更新失败时，自旋重试如果长时间不成功，会给CPU带来非常大的执行开销。

- **只能保证一个共享变量的原子操作（CAS）**

- - CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。
  - 可以用锁，或者把多个共享变量合并成一个共享变量来操作。



### 锁的实现主要要处理问题

1. **在哪里储存“谁拿到锁”的信息**
   - 可以是当前class，当前instance的markword
   - 还可以是某个具体的Lock的实例
2. **抢锁的规则**
   - 只能一个人抢到 - Mutex互斥锁；
   - 能抢有限多个数量 - Semaphore信号量；
   - 自己可以反复抢 - 重入锁；
   - 读可以反复抢到但是写独占 - 读写锁
3. **抢不到时怎么办**
   - 抢不到玩命抢-自旋锁；
   - 抢不到暂时睡着，等一段时间再试/等通知再试-互斥锁；
   - 或者二者的结合，先玩命抢几次，还没抢到就睡着
4. **如果锁被释放了还有其他等待锁的怎么办**
   - 不管，让等的线程通过超时机制自己抢；
   - 按照一定规则通知某一个等待的线程；
   - 通知所有线程唤醒他们，让他们一起抢



## 死锁

### 概念

1. 两个及以上的进程因争夺资源而造成的一种**互相等待**的现象；
2. 若无**外力**作用，它们将永远等待而无法推进下去。



### 产生原因

1. 系统资源不足。
2. 进程运行推进顺序不合适。
3. 资源分配不当

 

### 必要条件

1. 互斥：一个资源每次只能被一个进程使用。
2. 请求与保持：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不可剥夺：分配个给一个进程的资源不能被强制剥夺，只能被占有它的进程显式地释放。
4. 循环等待：若干进程之间形成一种循环等待资源的关系。



### 处理方法

#### 鸵鸟策略

1. 不采取任何措施
2. 适合死锁时不会对用户造成很大影响，或死锁率很低的情况。



#### 死锁检测与恢复

- 不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

1. **检测**

   - 每种资源类型只有一个实例的情况：通过检测有向图是否存在环来实现
     - 构建资源分配有向图，
     - 深度优先遍历确认有向图是否存在环路

   - 每种资源类型有多个实例的情况：构建资源数量的向量矩阵，模拟资源分配
     - 寻找一个可以完成运行的进程Pi，该进程请求资源数量小于等于现存资源向量；
     - 释放其所持有的资源到现存资源向量中，该进程被标记为完成；
     - 重复执行，直到未找到可以完成的进程，
     - 若最后有进程未被标记为完成，则其为死锁进程

2. **恢复**

   - 抢占：将资源从一个进程强行取走给另一个进程且不通知原进程，用完后送回。
   - 回滚：记录检查点状态，检测到死锁时将程序回滚到上一个检查点的状态。
   - 杀死：杀死环中的一个或多个进程释放资源（最好为重运行不会造成太大影响的进程）。

   

#### 死锁预防

在程序运行之前预防发生死锁。

1. **破坏互斥条件**

   - 通常不可破坏	
   - 假脱机打印机技术允许若干个进程同时输出，因为只有打印机守护进程在请求物理打印机。

2. **破坏请求与保持条件**

   - 如规定所有进程在开始执行前请求所需要的全部资源。
3. **破坏不可剥夺条件**
   - 如果进程请求其他资源被拒绝，则必须释放它已经占有的资源
   - 若进程请求被另一进程占有的资源，则系统强制另一进程释放资源。

4. **破坏环路等待**

   - 如给资源统一编号，进程只能按编号顺序来请求资源。
   - 保证每个进程只能占用一个资源，若要请求另外一个资源，必须先释放第一个资源。

   

#### 死锁避免

1. 概念：
   - 在程序运行时避免进入不安全状态，发生死锁。
   - 本质上来说是不可能的，因为它需要获知未来的请求，而这些请求是不可知的。
2. **安全状态**

   - 在所有进程请求其最大需求资源的情况下，仍存在某种调度次序使每个进程都运行完毕。
3. **银行家算法**
   - 与死锁的检测相似，矩阵O表示每个进程已分配的资源向量，矩阵R表示每个进程还需要的资源向量，向量A表示剩余资源。
     - 在R中查找是否存在一行小于A，若没有，则系统将会发生死锁，状态是不安全的。
     - 若找到，则将该进程标记为完成，并将其资源加入到A中
     - 重复以上步骤，直到所有进程标记为完成，此时状态是安全的。



## 生产者消费者模型（有限缓冲模型）

1. **有限缓冲类**

   ```cpp
   #include <condition_variable>
   #include <mutex>
   #include <queue>
   
   class BoundedBuffer {
   public:
       BoundedBuffer(const BoundedBuffer& rhs) = delete;
       BoundedBuffer& operator=(const BoundedBuffer& rhs) = delete;
   
       BoundedBuffer(std::size_t size)
         : capacity_(size){
       }
   
       void Produce(int n) 
       {
           {
               std::unique_lock<std::mutex> lock(mutex_);
               // 等待缓冲不为满。
               not_full_cv_.wait(lock, 
                 [=] { return buffer_.size()< capacity_; });
               // 插入新的元素，更新下标。
               buffer_.push(n);
           }  // 通知前，自动解锁。
           // 通知消费者。
           not_empty_cv_.notify_one();
       }
       
       int Consume() 
       {
           std::unique_lock<std::mutex> lock(mutex_);
           // 等待缓冲不为空。
           not_empty_cv_.wait(lock, [=] { return buffer_.size() > 0; });      
           // 移除一个元素。
           int n = buffer_.top();
           buffer_.pop();
           // 通知前，手动解锁。
           lock.unlock();
           // 通知生产者。
           not_full_cv_.notify_one();
           return n;
       }
   
   private:
       std::size_t capacity_;
       std::queue<int> buffer_;
       std::condition_variable not_full_cv_;
       std::condition_variable not_empty_cv_;
       std::mutex mutex_;
   };
   ```

   

2. **主程序**

   ```cpp
   BoundedBuffer g_buffer(2);
   boost::mutex g_io_mutex;		//用来同步输出
   
   //生产者：生产 100000 个元素，每 10000 个打印一次。
   void Producer() 
   {
       int n = 0;
       while (n < 100000) 
       {
           g_buffer.Produce(n);
           if ((n % 10000) == 0) 
           {
               std::unique_lock<std::mutex> lock(g_io_mutex);
               std::cout << "Produce: " << n << std::endl;
           }
           ++n;
       }
       g_buffer.Produce(-1);
   }
   
   //消费者：每消费到 10000 的倍数，打印一次。
   void Consumer() 
   {
       std::thread::id thread_id = std::this_thread::get_id();  
       int n = 0;
       do 
       {
   	    n = g_buffer.Consume();
   	    if ((n % 10000) == 0) 
   	    {
               std::unique_lock<std::mutex> lock(g_io_mutex);
               std::cout <<"Consume: "<<n<<" ("<<thread_id<<")"<<std::endl;
   	    }
       } while (n != -1);  // -1 表示缓冲已达末尾。
       
       // 往缓冲里再放一个 -1，这样其他消费者才能结束。
       g_buffer.Produce(-1);
   }
   
   
   //一个生产者线程，三个消费者线程。
   int main() 
   {
   	std::vector<std::thread> threads;
   	threads.push_back(std::thread(&Producer));
   	threads.push_back(std::thread(&Consumer));
   	threads.push_back(std::thread(&Consumer));
   	threads.push_back(std::thread(&Consumer));
   	for (auto& t : threads) t.join();
   
   	return 0;
   }
   ```

   

# 内存管理

### 存储体系

1. **寄存器（Register）**
   - CPU的组成部份；
   - 寄存器是有限存贮容量的高速存贮部件，用来暂存指令、数据和位址；
   - CPU控制部件中有指令寄存器(IR)和程序计数器(PC)，算术及逻辑部件中有累加器(ACC)。
2. **内存**
   - **只读存储器（Read Only Memory，ROM）**
     - 通常是一块在硬件上集成的可读芯片，作用是识别与控制硬件
     - 早期的ROM只可读，不可写；
     - 现在的ROM可写，但速度不如RAM，可能需要特殊的擦写流程，且擦写次数有限
   - **随机存取存储器（****Random Access Memory，RAM）**
     - RAM分为静态RAM（Static RAM，SRAM）
       - 当数据被存入其中后不会消失；
       - 速度快价格贵，是目前读写最快的存储设备；
     - 动态RAM（Dynamic RAM/DRAM）
       - 必须在一定的时间内不停的刷新才能保持其中存储的数据；
       - 通常意义下的内存一般指DRAM；
   - **缓存（cache）**
     - 为了调和CPU得过快访问速度和内存过慢的速度，若直接从内存读则浪费CPU性能；
     - 通常使用的是SRAM，比内存快；
     - 一般有L1、L2、L3三级高速缓存，速度依次递减；
     - CPU读取顺序为L1、L2、L3、内存。



### 内存映射

最初的操作系统中，所有进程直接操作物理内存，且程序运行需要**足够大**的**连续**内存，并装载整个程序。这种方式存在以下问题：

1. 进程的内存无法隔离，可能被其他进程污染。
2. 程序运行时地址不确定：每次装载不保证都在同样的物理地址
3. 内存利用率低：切换程序时由于要以整个程序为单位，可能浪费内存。



### 虚拟内存

1. 通过虚拟地址空间，将硬盘上一些空间作为虚拟内存，让物理内存扩充成更大的逻辑内存；
2. 分段与分页的基础，程序操作虚拟地址，实现了内存隔离，解决了运行时地址不定的问题。



### 分段管理

1. 将程序分成代码段，数据段，堆栈段等**大小不等**的段；
2. 将虚拟地址空间映射到**连续的**物理地址空间，程序操作虚拟地址；
3. 虚拟地址转换为物理地址时，系统检测操作地址的合理性，从而实现了内存隔离；
4. 虚拟地址保持不变，无需关注物理地址，从而解决了程序运行时地址不确定的问题；
5. 以**整个程序**为单位进行换入换出，且映射连续的地址，内存碎片太大。



### 分页管理

1. 将虚拟地址空间映射到**不连续的**物理地址空间；
2. 将程序以4K为单位分成**等大的页**，内存也被分成等大的**页框**，用于装载页；
3. 以页为单位进行换入换出，允许将暂不使用的页换出到磁盘，使用时再换入；
4. 对用户来说没有逻辑意义，只是为了完成离散储存；



### 段页式

1. 分段与分页的结合；
2. 将程序分段，再将大小不等的段分为大小相等的页
3. 逻辑地址--> (分段地址转换) -->虚拟地址-->（分页地址转换) -->物理地址



### 内存管理单元（Memory Management Unit，MMU）

1. 通过页表进行虚拟地址空间到物理地址空间的映射；
2. 一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

3. 通过查询页表中的状态位可确定要访问的页是否在内存中；
4. 若不在，则产生缺页中断，然后操作系统根据页表在磁盘中找到所缺的页，将其调入内存；
5. 若缺页中断时，内存中没有空闲的页框，则需要将内存中某一页换出到磁盘

　

### 页面置换算法

1. **最佳置换（Optimal， OPT)**
   - 置换将来最迟被访问的页面，缺页中断率最低。
   - 是一种理论上的算法，因为无法预知一个页面多长时间才会被访问。
2. **先进先出（First In First Out, FIFO)**	
   - 置换最先调入内存的页面；
   - 会置换出经常访问的页面，从而使缺页率升高，目前已经很少使用。
3. **最近最久未使用（Least Recently Used， LRU）**
   - 置换最近一段时间以来最长时间未访问过的页面。
   - 在内存中维护一个所有页的链表，将刚访问的页移到表头，保证表尾为最久未使用。
   - 每次访问都需要更新链表，开销太大，因此LRU算法必须要有硬件的支持。
4. **最近未使用（Not Recently Used，NRU）**
   - 每个页有两个状态位R与M：访问页时设置其R=1，修改时设置M=1，且R会定时清零；
   - 随机置换一个类别编号最小的页；
   - 优先置换被修改的脏页面（R=0，M=1），而非频繁读取的干净页面（R=1，M=0）。
5. **第二次机会**
   - 为避免FIFO把经常使用的页置换出去，对其进行了优化
   - 页被读写时设置其R=1，置换时，检查R，若为1，则放到链表末尾，若为0，则置换。
6. **时钟**
   - 第二次机会算法的优化，将链表首位相连，再用指针指向最老页。
   - 避免了置换时移动页。
   - 置换时，检查R，若为1，指针向前，若为0，置换。



## 操作系统的内核态和用户态

1. 为了维持系统的安全性与稳定性，控制系统资源的访问，操作系统设置了Ring0-Ring3四个访问控制级别。Ring0对应内核态，Ring3对应用户态。
2. 某些操作只有在内核态下才能运行，能有效保护硬件资源的安全。
3. 用户程序在请求一些特权操作时，需要通过系统调用切换到内核态后执行。
4. 用户程序进行系统调用后，操作系统执行一系列的检查验证安全后，才予以执行。







多线程/多进程的优势和劣势（n核CPU的线程数怎么选择）

· 文件系统（inode）、内存系统（虚拟内存）